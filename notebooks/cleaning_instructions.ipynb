{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17963993-a2d2-4927-8ce8-7ad43a9b15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce6dd4-7258-4e6c-8f75-13aea2cf0dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_comments =pd.read_csv(r'..\\data\\raw\\reddit_comments_combined.csv')\n",
    "reddit_comments.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3b8ba-7b18-4c4c-97b9-1eb022a241c5",
   "metadata": {},
   "source": [
    "## Clean column name by lower and replace white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292607e-6eca-45c0-8d49-8a045f4af12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clean column name-1 change to lower letter and replace white space with _ null values\n",
    "reddit_comments.columns = (\n",
    "reddit_comments.columns.str.lower().str.replace(\" \", \"_\").str.strip()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4564e7-e27a-4d85-bbf2-7a648e4f12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. View nulls\n",
    "print(\"Missing values per column:\\n\", reddit_comments.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ce0d6-2793-4bee-b403-7ff829104dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    " for col in reddit_comments.columns:\n",
    "    if reddit_comments[col].isnull().sum() == 0:\n",
    "        continue  # Skip columns with no missing values\n",
    "    \n",
    "    if reddit_comments[col].dtype == 'object':\n",
    "        mode_val = reddit_comments[col].mode()\n",
    "        if not mode_val.empty:\n",
    "            reddit_comments[col] = reddit_comments[col].fillna(mode_val[0])\n",
    "        else:\n",
    "            reddit_comments[col] = reddit_comments[col].fillna(\"unknown\")  # fallback\n",
    "    else:\n",
    "        mean_val = reddit_comments[col].mean()\n",
    "        reddit_comments[col] = reddit_comments[col].fillna(mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008a94b-65c3-49ec-9463-db2bc6f5eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reddit_comments['comment_author'] = reddit_comments['comment_author'].fillna('anonymous')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67783f34-8a46-4998-ab53-3b8784826047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "reddit_comments = reddit_comments.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd30de-f8f1-4b6d-bd8f-26172749e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remaining nulls:\\n\", reddit_comments.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a79a2-bd40-4d9b-a367-f6a6f08e21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Drop duplicates and reset index\n",
    "reddit_comments = reddit_comments.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a2c4a0-e702-4b80-80ff-9f906e9439b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final shape:\", reddit_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596b04c-2979-4556-b92f-a7fd6cc2fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_comments.to_csv(r'..\\data\\clean\\ai_job_sentiments.csv', index=False, encoding='utf-8', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc774ef-8a0d-44dd-bda7-290cd504e682",
   "metadata": {},
   "source": [
    "                                      ## CLEANING OF EMPLOYMENT PROJECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3063c11-c90f-4f32-81a3-e358ce0812f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f56e9-c1a4-49ca-93f8-b04571cd86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Employment_projections = pd.read_csv(r'..\\data\\raw\\Employment_projections.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52935c3e-400a-4263-a6c3-6e7f0f635f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clean column names\n",
    "Employment_projections.columns = Employment_projections.columns.str.lower().str.replace(\" \", \"_\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe05d51-47b9-45c1-969e-001088756603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. View nulls\n",
    "print(\"Missing values per column:\\n\", Employment_projections.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cee13d-c0b0-4c33-a889-8d797b337029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582d9fd-59c7-41ba-b9d8-c86be6869fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\").str.replace(\",\", \"\").str.strip()\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdbc07-a5b9-476a-b92d-67e084ae0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['work_experience_in_a_related_occupation'] = df['work_experience_in_a_related_occupation'].fillna('Not Required')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee00ab-6405-45f4-971a-27cd8a19fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['typical_on-the-job_training'] = df['typical_on-the-job_training'].fillna('None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba39e9a-3da7-4c34-a27b-f3a66607221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Employment_projections.to_csv(r'..\\data\\clean\\Employment_projection.csv', index=False, encoding='utf-8', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b818780-29a9-4d14-bd9b-a8463ffff66c",
   "metadata": {},
   "source": [
    "                                           ## CLEANING OF OCCUPATION GROWTH"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12cf3f55-488f-4bf0-9106-9ee17bd6f6a8",
   "metadata": {},
   "source": [
    "print(df[['work_experience_in_a_related_occupation', 'typical_on-the-job_training']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f089cc-78ed-49ff-84b9-824b9b2eec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_growth= pd.read_csv(r'..\\data\\clean\\occupation_growth.csv')\n",
    "occupation_growth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c39870-3e86-4511-914e-39a17ea69f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean column names\n",
    "occupation_growth.columns = (\n",
    "    occupation_growth.columns\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\",\", \"\")\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2358de-0d13-4c1e-a105-ed662092131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(occupation_growth.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbbce0a-6c47-4966-be01-54160ca3296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and reset index\n",
    "occupation_growth = occupation_growth.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613886e-8cc0-41be-b84c-d66ffdb4efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_growth.to_csv(r'..\\data\\clean\\occupation_growth_cleaned.csv', index=False, encoding='utf-8', sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3ba2c-7744-4368-9f66-1fd46b36b686",
   "metadata": {},
   "source": [
    "                                    ## CLEANING  OF   ALL_DATA_ SET_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303383a2-6c93-465d-b7f3-5b4d4351e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Reload the re-uploaded file after reset\n",
    "file_path =r'../data/raw/all_data_M_2024.csv'\n",
    "\n",
    "# Attempt to load while skipping problematic lines\n",
    "try:\n",
    "    all_data_df = pd.read_csv(\n",
    "        file_path,\n",
    "        quoting=csv.QUOTE_MINIMAL,\n",
    "        encoding='utf-8',\n",
    "        on_bad_lines='skip'  # skips problematic lines\n",
    "    )\n",
    "    cleaned_preview = all_data_df.head()\n",
    "except Exception as e:\n",
    "    cleaned_preview = f\"Error during loading: {e}\"\n",
    "\n",
    "cleaned_preview\n",
    "# Reload the file using semicolon delimiter\n",
    "all_data_df = pd.read_csv(file_path, delimiter=';', encoding='utf-8', on_bad_lines='skip')\n",
    "\n",
    "# Show the cleaned preview\n",
    "all_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0991c0-a9e6-48f6-824d-022351f8ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    " #2. Clean column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\",\", \"\")\n",
    "    .str.strip()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d08105-6a1b-4374-8812-323475a465b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Print missing values for review\n",
    "print(\"Missing values before cleaning:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af812a-3bba-4144-bfee-ec7773b9551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate columns (e.g. measure, time_period, etc.)\n",
    "df = df.loc[:, ~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cd758-006c-4822-9b44-3ee79fd3b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 90% missing values\n",
    "missing_ratio = df.isnull().mean()\n",
    "cols_to_drop = missing_ratio[missing_ratio > 0.9].index\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "print(f\"Dropped columns with >90% missing values:\\n{list(cols_to_drop)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff09d8-20df-4553-b495-5cad4d0409db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e8b82-ba44-4c7e-a5ac-fc83d81b922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf47950-f115-4821-a6db-45f81a3ebbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() == 0:\n",
    "        continue\n",
    "    if df[col].dtype == 'object':\n",
    "        mode_val = df[col].mode()\n",
    "        df[col] = df[col].fillna(mode_val[0] if not mode_val.empty else \"unknown\")\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f1d6a-1ee6-4c0f-8571-0527df0edd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to convert any remaining object columns to numeric\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].replace(r'[,\\$]', '', regex=True)\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except:\n",
    "            pass  # leave as object if not convertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a82c7-53d8-496c-9c77-a8fc99eb82c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44063d-7f3f-49f5-b30b-1312185f791e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Final shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2407f0-a29d-4ef7-b153-47ef5c77513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'..\\data\\clean\\all_data_M_2024_cleaned.csv', index=False, encoding='utf-8', sep=\";\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "251e5e98-568e-4a4d-a004-720d802eb5fc",
   "metadata": {},
   "source": [
    "                                                       CLEANING OF OECD RAW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89995739-7198-4d66-bbda-4f69aea3c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/raw/Oecd.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38688ca-a7f0-4736-8e12-99d877ae9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\",\", \"\")\n",
    "    .str.replace(\"@\", \"\")\n",
    "    .str.replace(\"+\", \"\")\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d134410-3145-4ff6-af1f-b7fc7e34f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Check for missing values\n",
    "print(\"Missing values before cleaning:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865f12a-8319-4c7b-955b-aff9ff7479bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop exact duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2fd9b6-6ce6-4bdf-bad5-ff4a141355f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with > 90% missing values\n",
    "threshold = 0.9\n",
    "missing_ratio = df.isnull().mean()\n",
    "columns_to_drop = missing_ratio[missing_ratio > threshold].index\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70daa58-15cb-4b35-82f7-928e111f7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns dropped due to high missing values:\\n\", list(columns_to_drop))\n",
    "\n",
    "# Fill remaining missing values\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() == 0:\n",
    "        continue\n",
    "    if df[col].dtype == 'object':\n",
    "        mode_val = df[col].mode()\n",
    "        df[col] = df[col].fillna(mode_val[0] if not mode_val.empty else 'unknown')\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07d56b-292e-4ac5-8f3f-bafdbf45b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = df.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521a8b7-d5fa-4fec-a027-fd4a672aa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cleaned Oecd dataset saved. Final shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa5315-7912-4ba5-9146-f5f34731b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'..\\data\\clean\\Oecd_cleaned.csv', index=False, encoding='utf-8', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5c1bb-a351-487e-9343-c4fbe6666705",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning invalid Values/row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8addeb-85bb-455d-b409-53ee7601dbc9",
   "metadata": {},
   "source": [
    "## Formatting data types\n",
    "Dealing with Null values\n",
    "Identify any columns with null or missing values. Identify how many null values each column has. You can use the isnull() function in pandas to find columns with null values.\n",
    "\n",
    "Decide on a strategy for handling the null values. There are several options, including:\n",
    "\n",
    "Drop the rows or columns with null values\n",
    "Fill the null values with a specific value (such as the column mean or median for numerical variables, and mode for categorical variables)\n",
    "Fill the null values with the previous or next value in the column\n",
    "\n",
    "-- Implement your chosen strategy to handle the null values. You can use the fillna() function in pandas to fill null values or dropna() function to drop null values.\n",
    "\n",
    "Verify that your strategy has successfully handled the null values. You can use the isnull() function again to check if there are still null values in the dataset.\n",
    "\n",
    "Remember to document your process and explain your reasoning for choosing a particular strategy for handling null values.\n",
    "\n",
    "After formatting data types, as a last step, convert all the numeric variables to integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050f0ab-c128-4be9-801a-4acb7667d1fc",
   "metadata": {},
   "source": [
    " ## Dealing with duplicates\n",
    "Use the .duplicated() method to identify any duplicate rows in the dataframe.\n",
    "\n",
    "Decide on a strategy for handling the duplicates. Options include:\n",
    "\n",
    "Dropping all duplicate rows\n",
    "Keeping only the first occurrence of each duplicated row\n",
    "Keeping only the last occurrence of each duplicated row\n",
    "Dropping duplicates based on a subset of columns\n",
    "Dropping duplicates based on a specific column\n",
    "Implement your chosen strategy using the drop_duplicates() function.\n",
    "\n",
    "Verify that your strategy has successfully handled the duplicates by checking for duplicates again using .duplicated().\n",
    "\n",
    "Remember to document your process and explain your reasoning for choosing a particular strategy for handling duplicates.\n",
    "\n",
    "Save the cleaned dataset to a new CSV file.\n",
    "\n",
    "Hint: after dropping duplicates, reset the index to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea7cdb-3b57-4c55-bb03-00e19674d839",
   "metadata": {},
   "source": [
    "## Creating functions on a separate py file\n",
    "Put all the data cleaning and formatting steps into functions, and create a main function that performs all the cleaning and formatting.\n",
    "\n",
    "Write these functions in separate .py file(s). By putting these steps into functions, we can make the code more modular and easier to maintain.\n",
    "\n",
    "Hint: autoreload module is a utility module in Python that allows you to automatically reload modules in the current session when changes are made to the source code. This can be useful in situations where you are actively developing code and want to see the effects of changes you make without having to constantly restart the Python interpreter or Jupyter Notebook kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43968208-c1ae-41bc-bb73-6e18d589bf42",
   "metadata": {},
   "source": [
    "## Analyzing Clean and Formated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fec34-1961-4d49-8643-cb766af2db64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
